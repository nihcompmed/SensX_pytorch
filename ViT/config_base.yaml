experiment:
  input_dir: "data/"
  output_dir: "analysis_results/"
  model_path: "./vit-Smiling-model-final"
  device: "cuda"

data_constraints:
  # Paths to numpy arrays defining the global hypercube
  global_lower_path: "global_lower.npy"
  global_upper_path: "global_upper.npy"
  
  # Path to numpy array containing indices of features to perturb
  # Set to null to perturb ALL features
  perturb_features_path: null
  # perturb_features_path: "constraints/active_indices.npy"

stability_analysis:
  # The list of delta values to scan in Step 1
  deltas: [0.05, 0.10, 0.15, 0.20, 0.25, 0.30, 0.35, 0.40, 0.45, 0.50, 0.55, 0.60, 0.65, 0.70, 0.75, 0.80, 0.85, 0.90, 0.95, 1.0]
  n_samples: 1000       # Number of random samples per delta (n_s)
  batch_size: 512        # Inference batch size for sampling

optimal_delta_search:
  tau_a: 0.1           # Max allowed variation (Max-Min) in the tail
  tau_r: 0.1            # Max allowed gradient magnitude in the tail

sensitivity_analysis:
  # Options: "feature_batching" (Default, for Images) or "input_batching" (For Tabular/Many inputs)
  method: "feature_batching"
  n_trajectories: 5   # Number of Morris trajectories (n_w)
  batch_size: 512        # Inference batch size for trajectory steps (vectorized chunks)
